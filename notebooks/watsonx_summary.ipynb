{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Summary Generation using watsonX Part - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from genai.extensions.langchain import LangChainInterface\n",
    "from genai.schemas import GenerateParams\n",
    "from genai.credentials import Credentials\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting up the API Key and Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"GENAI_KEY\", None)\n",
    "api_url = os.getenv(\"GENAI_API\", None)\n",
    "creds = Credentials(api_key, api_endpoint=api_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setting up the model name and its parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/llama-2-70b-chat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = GenerateParams(\n",
    "            decoding_method=\"greedy\",\n",
    "            max_new_tokens=300,\n",
    "            min_new_tokens=100,\n",
    "            temperature=0.7,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Function to store open the txt file, convert it in to embeddings and store it in vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_txt(): \n",
    "    pdf_name = 'transcriptios.txt'\n",
    "    loaders = [TextLoader(pdf_name)]\n",
    "\n",
    "    index = VectorstoreIndexCreator(\n",
    "        embedding = HuggingFaceEmbeddings(model_name='all-MiniLM-L12-v2'), \n",
    "        text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    ).from_loaders(loaders)\n",
    "\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create the object of the function and call it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charanahu/VS_Code/EMEA/Audio_Summary/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "index = load_txt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Deffining the PROMPT TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer in English:\n",
    "\n",
    "\n",
    "Person emotion on IBM: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Defing the chain with parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=LangChainInterface(model=model_id, params=params, credentials=creds), chain_type=\"stuff\", retriever=index.vectorstore.as_retriever(), chain_type_kwargs=chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Summary of the conversation: IBM has announced Watson X, a platform for building AI models for businesses. It's different from chat GPT and focuses on business use cases like customer service, IT automation, cybersecurity, and governance. IBM will earn money through the subscription platform and consulting services.\n",
      "\n",
      "2. Emotions on organization/company based on the conversation:\n",
      "\n",
      "Positive:\n",
      "\n",
      "* IBM is pleased to announce Watson X.\n",
      "* It's going to have a huge impact on businesses.\n",
      "* IBM is focused on business use cases.\n",
      "* IBM has built a capability for bringing data in that is trusted and understandable.\n",
      "* IBM has a center of excellence for generative AI.\n",
      "* IBM can monetize through software and consulting.\n",
      "\n",
      "Neutral:\n",
      "\n",
      "* IBM is working closely with Washington to evaluate the best way to regulate AI.\n",
      "\n",
      "No negative emotions are expressed towards IBM in the conversation.\n"
     ]
    }
   ],
   "source": [
    "query = '''1. Summary of the conversation: \\n\n",
    "                     \n",
    "        2. Emotions on organization/ company based on the conversation:'''\n",
    "\n",
    "\n",
    "print(qa.run(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
